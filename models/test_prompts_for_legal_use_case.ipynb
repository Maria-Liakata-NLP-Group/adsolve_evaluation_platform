{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d179edbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/sl318/.conda/envs/evaluation_mvp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from generations_pipeline import LLMGenerator\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b8dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into HuggingFace\n",
    "hf_token = \"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\" # Replace with your HuggingFace token\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106941a0",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load UK supreme court cases \n",
    "UK_CASES_PATH = \"/import/nlp-datasets/court_case_summarisation/datasets/UK-Abs/test-data\"\n",
    "\n",
    "# the data that needs to be summarised\n",
    "uk_cases_judgement = {}\n",
    "for root, dirs, files in os.walk(os.path.join(UK_CASES_PATH, \"judgement\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                uk_cases_judgement[file.split('.txt')[0]] = f.read()\n",
    "\n",
    "# gold summaries for reference (and later for evaluation)\n",
    "uk_cases_gold_summaries = {}\n",
    "for root, dirs, files in os.walk(os.path.join(UK_CASES_PATH, \"summary/full\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                uk_cases_gold_summaries[file.split('.txt')[0]] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a16bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes look at only one case for now. The index can be changed to test other cases\n",
    "CASE_INDEX = 0\n",
    "CASE_KEY = list(uk_cases_judgement.keys())[CASE_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b82792",
   "metadata": {},
   "source": [
    "### Initilaise generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea6c69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "initialise the LLM generator\n",
    "you can either use a model from HuggingFace e.g. \"meta-llama/Meta-Llama-3.1-8B-Instruct\" \n",
    "or you can type \"tulu\" to use the temporal reasoning model that Jiayu developed\n",
    "'''\n",
    "summariser = LLMGenerator(\n",
    "    model_name=\"tulu\",\n",
    ")\n",
    "\n",
    "# NOTE: it looks like the tulu model is not trained to take on a document that is as long as the UK supreme court cases\n",
    "# I'm getting the following error:\n",
    "# Token indices sequence length is longer than the specified maximum sequence length for this model (16100 > 4096). Running this sequence through the model will result in indexing errors\n",
    "# the summary still seems decent though"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea0b6c",
   "metadata": {},
   "source": [
    "### summarise in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f112792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16100 > 4096). Running this sequence through the model will result in indexing errors\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "# Let's first try a summary in just one round\n",
    "\n",
    "# Here is the prompt, I put absolutely no effort into this, it's just a proof of concept\n",
    "prompt = [\n",
    "    \"\"\"\n",
    "        You are a legal expert. Your task is to summarise the following UK Supreme Court case for a press release.\n",
    "        The summary should be concise, use plain english language and be separated in three sections: \n",
    "        ‘Background to the Appeal’, ‘Judgement’, and ‘Reasons for Judgement’.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Now let's generate the summary, \n",
    "case_to_summarise = [uk_cases_judgement[CASE_KEY]]\n",
    "# Generate the summary\n",
    "summary = summariser.run_summary(\n",
    "    prompt=prompt,\n",
    "    text=case_to_summarise,\n",
    "    max_tokens=[500],  # Limit the length of the summary\n",
    "    temperature=0.0,     # Adjust the creativity of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad187e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The judgment in the case of Treacy J, as discussed in the provided text, revolves around the legal powers of the Police Service of Northern Ireland (PSNI) under the 1998 Act in relation to the control of parades, particularly in the context of the flags protest in Belfast. The case highlights the complexities and challenges faced by the police in balancing the need to maintain public order with the rights of individuals to protest. The judgment underscores the importance of understanding the full scope of legal powers available to the police, the role of the Parades Commission, and the need for a proactive and informed approach to policing parades.\n",
      "\n",
      "The case of McGraddie v McGraddie, as referenced in the text, provides a framework for appellate courts reviewing findings made by trial judges. It emphasizes the principle of deference to the trial judge's findings, especially in cases where the trial judge has had the opportunity to assess the credibility of witnesses and the evidence presented. This principle is crucial in ensuring that appellate courts do not unduly interfere with the decisions made by trial judges, who are in a better position to evaluate the evidence and make factual determinations.\n",
      "\n",
      "In the context of the flags protest in Belfast, the judgment in Treacy J highlights the challenges faced by the PSNI in interpreting their legal powers under the 1998 Act. The case illustrates the importance of a clear understanding of the law and the need for police to take a proactive approach in managing parades to prevent violence and ensure public safety. It also underscores the role of the Parades Commission in providing guidance and oversight in the management of parades, and the need for police to work closely with this body to ensure that parades are conducted in a lawful and orderly manner.\n",
      "\n",
      "Overall, the judgment in Treacy J and the case of McGraddie v McGraddie provide valuable insights into the legal and practical challenges faced by the police in managing parades and ensuring public order. They highlight the importance of a clear understanding of the law, a proactive approach to policing, and effective collaboration with oversight bodies in ensuring that parades are conducted in a lawful and orderly manner. Bob,\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece5465",
   "metadata": {},
   "source": [
    "### summarise the dataset in two rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4a8ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      2\u001b[39m prompt = [\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m        You are a helpful assistant. Look at the following document from a UK Supreme Court and summarise it.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m ]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# I'm splitting the case into smaller chunks. The approach here is just dividing the case into 4 parts, this is not a sophisticated approach\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# because it does not take into account the structure of the document\u001b[39;00m\n\u001b[32m     16\u001b[39m case_to_summarise = [\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43muk_cases_judgement\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m4\u001b[39m],\n\u001b[32m     18\u001b[39m     uk_cases_judgement[\u001b[32m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m4\u001b[39m: \u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m2\u001b[39m],\n\u001b[32m     19\u001b[39m     uk_cases_judgement[\u001b[32m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m2\u001b[39m: \u001b[32m3\u001b[39m * \u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m4\u001b[39m],\n\u001b[32m     20\u001b[39m     uk_cases_judgement[\u001b[32m0\u001b[39m][\u001b[32m3\u001b[39m * \u001b[38;5;28mlen\u001b[39m(uk_cases_judgement[CASE_KEY]) // \u001b[32m4\u001b[39m:]\n\u001b[32m     21\u001b[39m ]\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Generate the summary in two steps\u001b[39;00m\n\u001b[32m     23\u001b[39m summary = summariser.run_summary(\n\u001b[32m     24\u001b[39m     prompt=prompt,\n\u001b[32m     25\u001b[39m     text=case_to_summarise,\n\u001b[32m     26\u001b[39m     max_tokens=[\u001b[32m200\u001b[39m, \u001b[32m500\u001b[39m],  \u001b[38;5;66;03m# Limit the length of the summary\u001b[39;00m\n\u001b[32m     27\u001b[39m     temperature=\u001b[32m0.0\u001b[39m,     \u001b[38;5;66;03m# Adjust the creativity of the output\u001b[39;00m\n\u001b[32m     28\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# Here are two prompts, one to reduce the length of the document and a second one to produce the final summary., I put absolutely no effort into this, it's just a proof of concept\n",
    "prompt = [\n",
    "    \"\"\"\n",
    "        You are a helpful assistant. Look at the following document from a UK Supreme Court and summarise it.\n",
    "        Your goal is to produce a concise summary that only contains information relevant to a legal journalist.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "        You are a legal expert. Your task is to summarise the following summaries of a UK Supreme Court case for a press release.\n",
    "        The summary should be concise, use plain english language and be separated in three sections: \n",
    "        ‘Background to the Appeal’, ‘Judgement’, and ‘Reasons for Judgement’.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# I'm splitting the case into smaller chunks. The approach here is just dividing the case into 4 parts, this is not a sophisticated approach\n",
    "# because it does not take into account the structure of the document\n",
    "case_to_summarise = [\n",
    "    uk_cases_judgement[CASE_KEY][:len(uk_cases_judgement[CASE_KEY]) // 4],\n",
    "    uk_cases_judgement[CASE_KEY][len(uk_cases_judgement[CASE_KEY]) // 4: len(uk_cases_judgement[CASE_KEY]) // 2],\n",
    "    uk_cases_judgement[CASE_KEY][len(uk_cases_judgement[CASE_KEY]) // 2: 3 * len(uk_cases_judgement[CASE_KEY]) // 4],\n",
    "    uk_cases_judgement[CASE_KEY][3 * len(uk_cases_judgement[CASE_KEY]) // 4:]\n",
    "]\n",
    "# Generate the summary in two steps\n",
    "summary = summariser.run_summary(\n",
    "    prompt=prompt,\n",
    "    text=case_to_summarise,\n",
    "    max_tokens=[200, 500],  # Limit the length of the summary\n",
    "    temperature=0.0,     # Adjust the creativity of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69248a60",
   "metadata": {},
   "source": [
    "### load gold summary for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uk_cases_gold_summaries[CASE_KEY])  # Print the gold summary for comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
