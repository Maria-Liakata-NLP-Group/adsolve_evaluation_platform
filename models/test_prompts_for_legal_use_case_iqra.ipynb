{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d179edbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/sl318/.conda/envs/evaluation_mvp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from generations_pipeline import LLMGenerator\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b8dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into HuggingFace\n",
    "hf_token = \"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\" # Replace with your HuggingFace token\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b2c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(os.path.abspath(\".\"), \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106941a0",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load UK supreme court cases \n",
    "UK_CASES_PATH = \"/import/nlp-datasets/court_case_summarisation/datasets/UK-Abs/test-data\"\n",
    "\n",
    "# the data that needs to be summarised\n",
    "uk_cases_judgement = {}\n",
    "for root, dirs, files in os.walk(os.path.join(UK_CASES_PATH, \"judgement\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                uk_cases_judgement[file.split('.txt')[0]] = f.read()\n",
    "\n",
    "# gold summaries for reference (and later for evaluation)\n",
    "uk_cases_gold_summaries = {}\n",
    "for root, dirs, files in os.walk(os.path.join(UK_CASES_PATH, \"summary/full\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                uk_cases_gold_summaries[file.split('.txt')[0]] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a16bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes look at only one case for now. The index can be changed to test other cases\n",
    "CASE_INDEX = 0\n",
    "CASE_KEY = list(uk_cases_judgement.keys())[CASE_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b82792",
   "metadata": {},
   "source": [
    "### Initilaise generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea6c69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "initialise the LLM generator\n",
    "you can either use a model from HuggingFace e.g. \"meta-llama/Meta-Llama-3.1-8B-Instruct\" \n",
    "or you can type \"tulu\" to use the temporal reasoning model that Jiayu developed\n",
    "'''\n",
    "summariser = LLMGenerator(\n",
    "    model_name=\"tulu\",\n",
    ")\n",
    "\n",
    "# NOTE: it looks like the tulu model is not trained to take on a document that is as long as the UK supreme court cases\n",
    "# I'm getting the following error:\n",
    "# Token indices sequence length is longer than the specified maximum sequence length for this model (16100 > 4096). Running this sequence through the model will result in indexing errors\n",
    "# the summary still seems decent though"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea0b6c",
   "metadata": {},
   "source": [
    "### summarise in one go zerosot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OUTPUT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    123\u001b[39m final_summary_text = trim_incomplete_sentence(final_summary_text)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Ensure output directory exists before saving\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m os.makedirs(\u001b[43mOUTPUT_DIR\u001b[49m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    130\u001b[39m output_path = os.path.join(OUTPUT_DIR, \u001b[33m\"\u001b[39m\u001b[33muk_case_summary2.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'OUTPUT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Improved prompt for chunk summarization with emphasis on completeness and no hallucination\n",
    "prompt = [\n",
    "    \"\"\"\n",
    "    You are a legal expert tasked with summarizing the UK Supreme Court case text provided.\n",
    "\n",
    "    Please only summarize information explicitly contained in the text. Do NOT add any information, assumptions, or interpretations beyond what is clearly stated.\n",
    "\n",
    "    Structure your summary in three clearly marked sections with headings:\n",
    "    1. Background to the Appeal\n",
    "    2. Judgement\n",
    "    3. Reasons for Judgement\n",
    "\n",
    "    Use plain English, avoid legal jargon where possible. Be concise and factual. Do not repeat information.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Do NOT hallucinate or add any unsupported details.\n",
    "    - Only include facts present in the text.\n",
    "    - Ensure all sentences are complete and the summary ends logically and clearly.\n",
    "    - Do not cut off sentences abruptly or leave incomplete thoughts.\n",
    "\n",
    "    Limit the length to approximately 700 words.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Improved prompt for final refinement (combining chunk summaries)\n",
    "refine_prompt = [\n",
    "    \"\"\"\n",
    "    You are a legal expert tasked with combining multiple summaries of a UK Supreme Court case.\n",
    "\n",
    "    Only use information explicitly present in the provided summaries. Do NOT add, infer, or assume any details not contained in the text.\n",
    "\n",
    "    Structure the combined summary in three clearly marked sections with headings:\n",
    "    1. Background to the Appeal\n",
    "    2. Judgement\n",
    "    3. Reasons for Judgement\n",
    "\n",
    "    Use plain English, avoid legal jargon where possible. Be concise and factual. Avoid repetition.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Do NOT hallucinate or include unsupported information.\n",
    "    - Ensure all sentences are complete and the summary ends logically and clearly.\n",
    "    - Do not cut off sentences abruptly or leave incomplete thoughts.\n",
    "\n",
    "    Limit the overall length to approximately 700 words.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "def chunk_text_by_chars(text, max_chunk_chars=14000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_len = len(text)\n",
    "    \n",
    "    while start < text_len:\n",
    "        end = min(start + max_chunk_chars, text_len)\n",
    "        chunk = text[start:end]\n",
    "        \n",
    "        # Try to break at last period to avoid splitting sentences\n",
    "        if end < text_len:\n",
    "            last_period = chunk.rfind('.')\n",
    "            if last_period != -1 and last_period > max_chunk_chars * 0.5:\n",
    "                end = start + last_period + 1\n",
    "                chunk = text[start:end]\n",
    "\n",
    "        chunks.append(chunk.strip())\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "def trim_incomplete_sentence(text):\n",
    "    \"\"\"\n",
    "    Trim trailing incomplete sentence from text.\n",
    "    Keeps only complete sentences ending with ., !, or ?\n",
    "    \"\"\"\n",
    "    sentences = re.findall(r'.*?[.!?]', text, flags=re.DOTALL)\n",
    "    if sentences:\n",
    "        return ' '.join(sentences).strip()\n",
    "    else:\n",
    "        # No sentence ends found, return original text\n",
    "        return text.strip()\n",
    "\n",
    "# Replace with your actual case text and key\n",
    "long_text = uk_cases_judgement[CASE_KEY]\n",
    "\n",
    "# Model limits\n",
    "max_model_tokens = 3500\n",
    "max_chars_per_chunk = max_model_tokens * 4  # Approximate token to char ratio\n",
    "\n",
    "# Split into chunks\n",
    "chunks = chunk_text_by_chars(long_text, max_chars_per_chunk)\n",
    "\n",
    "chunk_summaries = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    summary = summariser.run_summary(\n",
    "        prompt=prompt,\n",
    "        text=[chunk],\n",
    "        max_tokens=[700],  # limit tokens per chunk summary\n",
    "        temperature=0,     # reduce hallucination by limiting creativity\n",
    "        # top_p=1.0,         # optional, keep full token probability distribution\n",
    "    )\n",
    "    if isinstance(summary, list) and len(summary) == 1:\n",
    "        chunk_summaries.append(summary[0])\n",
    "    else:\n",
    "        chunk_summaries.append(str(summary))\n",
    "\n",
    "combined_summary_text = \"\\n\\n\".join(chunk_summaries)\n",
    "\n",
    "final_summary = summariser.run_summary(\n",
    "    prompt=refine_prompt,\n",
    "    text=[combined_summary_text],\n",
    "    max_tokens=[700],  # max tokens for final summary\n",
    "    temperature=0,\n",
    "    # top_p=1.0,\n",
    ")\n",
    "\n",
    "if isinstance(final_summary, list) and len(final_summary) == 1:\n",
    "    final_summary_text = final_summary[0]\n",
    "else:\n",
    "    final_summary_text = str(final_summary)\n",
    "\n",
    "# Trim incomplete sentence at the end if any\n",
    "final_summary_text = trim_incomplete_sentence(final_summary_text)\n",
    "\n",
    "# Ensure output directory exists before saving\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(OUTPUT_DIR, \"uk_case_summary2.txt\")\n",
    "\n",
    "try:\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_summary_text)\n",
    "    print(f\"Summary successfully saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving summary: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b76e2",
   "metadata": {},
   "source": [
    " summarise the dataset in two rounds (Intermediate summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22d549",
   "metadata": {},
   "source": [
    "Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb66c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 summaries saved to /homes/sl318/adsolve_evaluation_platform/models/output/summaries_simple1/chunk_summaries.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Layer 1 prompt (simple chunk summarization)\n",
    "prompt = [\n",
    "    \"\"\"\n",
    "    You are an expert summarizer.\n",
    "\n",
    "    Summarize the given text clearly and simply, focusing only on the facts stated in the text.\n",
    "\n",
    "    Structure your summary in three clearly marked sections with these headings:\n",
    "    1. Background\n",
    "    2. Outcome\n",
    "    3. Explanation\n",
    "\n",
    "    Use plain English, avoid any jargon or technical terms. Be concise and factual. Do not repeat information.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Only include facts present in the text.\n",
    "    - Do NOT add assumptions or extra information.\n",
    "    - Ensure all sentences are complete and the summary ends clearly.\n",
    "    - Limit the summary to approximately 700 words.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "def chunk_text_by_chars(text, max_chunk_chars=14000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_len = len(text)\n",
    "\n",
    "    while start < text_len:\n",
    "        end = min(start + max_chunk_chars, text_len)\n",
    "        chunk = text[start:end]\n",
    "\n",
    "        if end < text_len:\n",
    "            last_period = chunk.rfind('.')\n",
    "            if last_period != -1 and last_period > max_chunk_chars * 0.5:\n",
    "                end = start + last_period + 1\n",
    "                chunk = text[start:end]\n",
    "\n",
    "        chunks.append(chunk.strip())\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Replace with your actual document text and key\n",
    "long_text = uk_cases_judgement[CASE_KEY]\n",
    "\n",
    "max_model_tokens = 3500\n",
    "max_chars_per_chunk = max_model_tokens * 4  # Approximate\n",
    "\n",
    "chunks = chunk_text_by_chars(long_text, max_chars_per_chunk)\n",
    "\n",
    "chunk_summaries = []\n",
    "for chunk in chunks:\n",
    "    summary = summariser.run_summary(\n",
    "        prompt=prompt,\n",
    "        text=[chunk],\n",
    "        max_tokens=[700],\n",
    "        temperature=0,\n",
    "    )\n",
    "    if isinstance(summary, list) and len(summary) == 1:\n",
    "        chunk_summaries.append(summary[0])\n",
    "    else:\n",
    "        chunk_summaries.append(str(summary))\n",
    "\n",
    "# Save chunk summaries to a file for layer 2\n",
    "output_dir = os.path.join(OUTPUT_DIR, \"summaries_simple1\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "layer1_output_path = os.path.join(output_dir, \"chunk_summaries.txt\")\n",
    "\n",
    "try:\n",
    "    with open(layer1_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for s in chunk_summaries:\n",
    "            f.write(s + \"\\n\\n\")\n",
    "    print(f\"Layer 1 summaries saved to {layer1_output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving layer 1 summaries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94608e8",
   "metadata": {},
   "source": [
    "Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c62df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 final summary saved to /homes/sl318/adsolve_evaluation_platform/models/output/summaries_legal/uk_case_summary2.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Layer 2 prompt (legal expert refinement)\n",
    "prompt = [\n",
    "    \"\"\"\n",
    "    You are a legal expert tasked with summarizing the UK Supreme Court case text provided.\n",
    "\n",
    "    Please only summarize information explicitly contained in the text. Do NOT add any information, assumptions, or interpretations beyond what is clearly stated.\n",
    "\n",
    "    Structure your summary in three clearly marked sections with headings:\n",
    "    1. Background to the Appeal\n",
    "    2. Judgement\n",
    "    3. Reasons for Judgement\n",
    "\n",
    "    Use plain English, avoid legal jargon where possible. Be concise and factual. Do not repeat information.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Do NOT hallucinate or add any unsupported details.\n",
    "    - Only include facts present in the text.\n",
    "    - Ensure all sentences are complete and the summary ends logically and clearly.\n",
    "    - Do not cut off sentences abruptly or leave incomplete thoughts.\n",
    "\n",
    "    Limit the length to approximately 700 words.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Layer 2 final refinement prompt (combining chunk summaries)\n",
    "refine_prompt = [\n",
    "    \"\"\"\n",
    "    You are a legal expert tasked with combining multiple summaries of a UK Supreme Court case.\n",
    "\n",
    "    Only use information explicitly present in the provided summaries. Do NOT add, infer, or assume any details not contained in the text.\n",
    "\n",
    "    Structure the combined summary in three clearly marked sections with headings:\n",
    "    1. Background to the Appeal\n",
    "    2. Judgement\n",
    "    3. Reasons for Judgement\n",
    "\n",
    "    Use plain English, avoid legal jargon where possible. Be concise and factual. Avoid repetition.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Do NOT hallucinate or include unsupported information.\n",
    "    - Ensure all sentences are complete and the summary ends logically and clearly.\n",
    "    - Do not cut off sentences abruptly or leave incomplete thoughts.\n",
    "\n",
    "    Limit the overall length to approximately 700 words.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "def trim_incomplete_sentence(text):\n",
    "    sentences = re.findall(r'.*?[.!?]', text, flags=re.DOTALL)\n",
    "    if sentences:\n",
    "        return ' '.join(sentences).strip()\n",
    "    else:\n",
    "        return text.strip()\n",
    "\n",
    "# Read chunk summaries from layer 1 output\n",
    "layer1_output_path = os.path.join(OUTPUT_DIR, \"summaries_simple1/chunk_summaries.txt\")\n",
    "\n",
    "try:\n",
    "    with open(layer1_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        combined_summary_text = f.read()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading layer 1 summaries: {e}\")\n",
    "    combined_summary_text = \"\"\n",
    "\n",
    "if combined_summary_text:\n",
    "    # Run first layer style summarization on combined summaries\n",
    "    chunk_summary = summariser.run_summary(\n",
    "        prompt=prompt,\n",
    "        text=[combined_summary_text],\n",
    "        max_tokens=[700],\n",
    "        temperature=0,\n",
    "    )\n",
    "    if isinstance(chunk_summary, list) and len(chunk_summary) == 1:\n",
    "        chunk_summary_text = chunk_summary[0]\n",
    "    else:\n",
    "        chunk_summary_text = str(chunk_summary)\n",
    "\n",
    "    # Final refinement combining chunk summaries\n",
    "    final_summary = summariser.run_summary(\n",
    "        prompt=refine_prompt,\n",
    "        text=[chunk_summary_text],\n",
    "        max_tokens=[700],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    if isinstance(final_summary, list) and len(final_summary) == 1:\n",
    "        final_summary_text = final_summary[0]\n",
    "    else:\n",
    "        final_summary_text = str(final_summary)\n",
    "\n",
    "    final_summary_text = trim_incomplete_sentence(final_summary_text)\n",
    "\n",
    "    output_dir = os.path.join(OUTPUT_DIR, \"summaries_legal\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, \"uk_case_summary2.txt\")\n",
    "\n",
    "    try:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_summary_text)\n",
    "        print(f\"Layer 2 final summary saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final summary: {e}\")\n",
    "else:\n",
    "    print(\"No combined summaries found to process in Layer 2.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69248a60",
   "metadata": {},
   "source": [
    "### load gold summary for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8cd1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Public Processions (Northern Ireland) Act 1998 (the 1998 Act) placed responsibility for the management of parades in Northern Ireland in the hands of an independent statutory body called the Parades Commission.\n",
      "The Act placed a duty on anyone proposing to organise a public procession to give advance notice to the police and made it a criminal offence to organise, or take part in, a public procession of which notification had not been given.\n",
      "On 3 December 2012 Belfast City Council decided to stop flying the Union flag over Belfast City Hall every day.\n",
      "The flag was to be flown on certain designated days only.\n",
      "The decision sparked a wave of protests by loyalists which continued for some months and became known as the flags protests.\n",
      "The protesters marched from a meeting point in East Belfast to Belfast City Hall in the centre of the city and back again.\n",
      "The route took the parade through the Short Strand, which is perceived to be a nationalist area, and where violence, disorder and sectarian abuse were directed at residents.\n",
      "No notification was made under the 1998 Act that a parade was due to take place.\n",
      "Initially, in order to prevent potential disorder, the police had taken the decision not to permit the protesters to enter Belfast City Centre.\n",
      "But between 6 and 8 December 2012 this decision was changed, as it was considered there was a need to try to facilitate some form of protest in order to ease community tension.\n",
      "Therefore, when the parades began on 8 December 2012 the protesters were permitted to enter the City Centre and pass through the Short Strand area.\n",
      "The weekly parades continued until March 2013, during which time the police took no action to stop them.\n",
      "The police made a number of public announcements to the effect that it had no power to stop a parade that had not been notified under the 1998 Act.\n",
      "They also tried, unsuccessfully, to refer the matter to the Parades Commission.\n",
      "The appellant, a resident of Short Strand, issued judicial review proceedings challenging the failure of the police to take action to prevent the parades from taking place.\n",
      "The High Court found that the police had failed to appreciate the extent of its powers to stop an un notified parade, which had the effect of undermining the 1998 Act.\n",
      "The Court of Appeal allowed the Chief Constables appeal.\n",
      "DB appealed to the Supreme Court.\n",
      "The Supreme Court unanimously allows DBs appeal and declares that the Police Service of Northern Ireland misconstrued their legal powers to stop parades passing through or adjacent to the Short Strand area.\n",
      "Lord Kerr gives the judgment, with which the other Justices agree.\n",
      "The flag protests presented the Police Service of Northern Ireland with enormous, almost impossible difficulties [1].\n",
      "There can be no suggestion that they failed to treat them with sufficient seriousness.\n",
      "This case is not about the sincerity and authenticity of those efforts, it is about whether, corporately, the police were sufficiently aware of the full range and scope of the powers available to them [3].\n",
      "The police have a duty, under the general law, to prevent the commission of offences.\n",
      "Participating in an un notified parade is a criminal offence under the 1998 Act and as such the police therefore had the power to prevent the parades.\n",
      "The police failed properly to appreciate this, instead believing that they only had a power to prevent the commission of general public order offences [10].\n",
      "The police were not required to form a judgment as to whether a parade should take place, but they were required to decide whether the parade was taking place legally.\n",
      "Failure to notify a proposed parade strikes at the heart of the effective functioning of the Parades Commission and therefore at the successful implementation of the 1998 Act.\n",
      "This Act represented a paradigm shift away from the old system where police were drawn into the controversial role of deciding which parades should be permitted to take place and under what conditions they should be allowed to proceed [63].\n",
      "The police failed to recognise that the integrity of the system depended on the enforcement of the requirement to notify an intention to hold a parade [64].\n",
      "It is the police, not the Parades Commission, who have the responsibility for preventing un notified parades from taking place [45].\n",
      "The police mistakenly believed that they were obliged by article 11 of the European Convention on Human Rights (freedom of assembly and association) to facilitate peaceful protests, even though they thought the protests were technically illegal.\n",
      "To the contrary, they had an inescapable duty to prevent, where possible, what were plainly illegal parades from taking place and to protect those whose rights under article 8 of the European Convention (respect for private life) were in peril of being infringed, subject to operational constraints.\n",
      "In general, a decision to disperse a parade or protest which has not been lawfully notified will not infringe article 11.\n",
      "There was no warrant for allowing article 11 considerations to determine how the parades should be policed [60 62].\n",
      "The High Court was therefore right to conclude that the police laboured under a misapprehension as to the extent of their powers [70].\n",
      "The polices policy did not, however, have the intention or the effect of undermining the 1998 Act [66].\n",
      "The police had an operational discretion in deciding how to respond to the parades.\n",
      "Discussion of what action might have been taken had the police properly understood the limits of their powers is unlikely to was unhelpful [74].\n",
      "Difficulties in making policing decisions should not be underestimated, especially since these frequently require to be made in fraught circumstances [76].\n",
      "The absence of a more proactive approach was not caused by police inertia, but by a concatenation of unfortunate circumstances, including misunderstandings about the powers available to them [77].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(uk_cases_gold_summaries[CASE_KEY])  # Print the gold summary for comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
