{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b514aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3924187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the JSON data\n",
    "with open('UK_Abs_test_data_jiayu_model_iqra_prompt.json', 'r') as file:\n",
    "    iqra_data = json.load(file)\n",
    "with open('UK_Abs_test_data_deepskeek-chat_prompt2_evaluation_results.json', 'r') as file:\n",
    "    deepskeek_data = json.load(file)\n",
    "with open('UK_Abs_test_data_gpt-4o_prompt2_evaluation_results.json', 'r') as file:\n",
    "    gpt4_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3d9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import summaries\n",
    "with open('/import/nlp-datasets/court_case_summarisation/generated_summaries/iqra_jiayu_model_summaries.json', 'r') as file:\n",
    "    iqra_summaries = json.load(file)\n",
    "with open('/import/nlp-datasets/court_case_summarisation/generated_summaries/UK_Abs_test_data_gpt-4o_prompt2.json', 'r') as file:\n",
    "    gpt_summaries = json.load(file)\n",
    "with open('/import/nlp-datasets/court_case_summarisation/generated_summaries/UK_Abs_test_data_deepseek-chat_prompt2.json', 'r') as file:\n",
    "    deepskeek_summaries = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ead73",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "        \"models\": [\"GPT_4o\", \"DeepSeek\", \"Jiayu\"],\n",
    "        \"datasets\": [\"UK_Abs\"],\n",
    "        \"metrics\": [\"readability\", \"intra_nli\", \"fc_expert\", \"conciseness\"],\n",
    "        \"metric_details\": {\n",
    "            \"readability\": \"Readability (Flesch-Kincaid Grade Level)\",\n",
    "            \"fc_expert\": \"Factual Consistency (FC_expert)\",\n",
    "            \"intra_nli\": \"Coherence (IntraNLI)\",\n",
    "            \"conciseness\": \"Conciseness (precision)\",\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e63aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_summaries = {id: item['reference'] for id, item in iqra_summaries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6605d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_dashboard = {\n",
    "    \"metadata\": metadata,\n",
    "    \"data\": {\n",
    "        \"UK_Abs\": {\n",
    "            \"gold_summary\": gold_summaries,\n",
    "            \"GPT_4o\": {\"llm_summary\": {id: item[\"summary\"] for id, item in gpt_summaries.items()},**gpt4_data},\n",
    "            \"DeepSeek\": {\"llm_summary\": {id: item[\"summary\"] for id, item in deepskeek_summaries.items()}, **deepskeek_data},\n",
    "            \"Jiayu\": {\"llm_summary\": {id: item[\"summary\"] for id, item in iqra_summaries.items()}, **iqra_data}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a JSON file\n",
    "with open('supreme-court-case-summarisation.json', 'w') as file:\n",
    "    json.dump(data_for_dashboard, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation_mvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
